# Linear vs Non-linear Classification with PyTorch

This project demonstrates how activation functions (like ReLU) enable neural networks to learn non-linear decision boundaries.

## Datasets Used
- Linearly separable data (from `make_classification`)
- Non-linear data (from `make_moons`)

## Models
- Linear Model: Only linear layers
- Non-Linear Model: Linear + ReLU layers

## Highlights
- Visualizes decision boundaries for both datasets
- Shows limitations of linear models

## Run
